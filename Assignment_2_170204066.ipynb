{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_2_170204066.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farhanSH/py/blob/master/Assignment_2_170204066.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "SHMiFJRmP3S-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "QJQFXwKJ7-1T"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import exp, array, random, dot\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# plotting\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from google.colab import drive\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset"
      ],
      "metadata": {
        "id": "sUHrWrsFP7Em"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/Dataset.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "uZCE1NLQ9VgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data visualization"
      ],
      "metadata": {
        "id": "oNJmwTnjQM5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentiment'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8AOhu8SQsZp",
        "outputId": "67362583-9cf0-4033-aa25-520dfcdefb4c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1, -1])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "4wiR1fcX-EPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the number of positive vs. negative tagged sentences\n",
        "\n",
        "#df['Sentiment'].value_counts()\n",
        "\n",
        "positives = df['Sentiment'][df.Sentiment == 1 ]\n",
        "negatives = df['Sentiment'][df.Sentiment == -1 ]\n",
        "\n",
        "print('Total length of the data is:         {}'.format(df.shape[0]))\n",
        "print('No. of positve tagged sentences is:  {}'.format(len(positives)))\n",
        "print('No. of negative tagged sentences is: {}'.format(len(negatives)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtUWL8DC-LpK",
        "outputId": "2210b98f-e8ed-4663-a82b-64ce5fabe85a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total length of the data is:         5791\n",
            "No. of positve tagged sentences is:  3685\n",
            "No. of negative tagged sentences is: 2106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df['Sentiment'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "-8xMHizL-pAQ",
        "outputId": "f1eff0c8-87eb-4702-9b4b-e24d4f225267"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f21bd86b150>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get a word count per of text\n",
        "def word_count(words):\n",
        "    return len(words.split())"
      ],
      "metadata": {
        "id": "Z4RsYvKOS0sc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk import word_tokenize, WordNetLemmatizer\n",
        "import nltk\n",
        "import re \n",
        "import string\n",
        "import pickle\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "GxtXI7kd_1KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words=set(stopwords.words('english'))\n",
        "print(stop_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNmEfFN0Oy4u",
        "outputId": "5a438434-f18c-4ff4-a99b-f033e942ef71"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'during', 'down', \"wouldn't\", 'than', 's', \"needn't\", 'because', 'ma', 'had', \"aren't\", 'too', 'mustn', 'against', 'how', 'each', 'his', 'through', 'ourselves', \"you'll\", 'into', 'again', 'she', 'mightn', 'very', 'our', 'their', 'here', 'should', \"mustn't\", 'm', 'which', 'before', 'her', 'this', 'when', 'having', 'is', 'by', 'him', \"she's\", 'on', 'of', 'we', 'same', 'with', 'both', \"it's\", 'below', \"mightn't\", 'in', 'himself', 'were', 'then', 'other', 'couldn', 'don', 'doesn', \"don't\", \"wasn't\", 'been', 'an', 'doing', 'at', 'between', 'out', 're', \"doesn't\", \"you've\", 'those', 'hasn', 'now', 'haven', 'only', 'after', 't', 'be', 'some', 'hadn', 'will', 'to', 'further', 'ours', 'until', 'hers', 'y', 'needn', 'yourselves', 'the', 'such', 'wouldn', \"won't\", 'll', 'ain', 'own', 'he', 've', 'above', \"shan't\", \"didn't\", 'didn', 'me', \"should've\", 'where', \"couldn't\", 'no', 'o', \"weren't\", 'over', 'yours', 'up', \"isn't\", 'you', 'most', 'all', 'was', 'once', 'myself', 'weren', 'why', 'these', 'from', 'few', 'as', \"that'll\", 'while', 'but', 'theirs', \"hasn't\", 'i', 'do', 'and', 'have', 'who', 'there', 'wasn', 'yourself', 'a', 'themselves', 'does', 'so', 'if', 'they', 'are', 'any', \"hadn't\", 'just', 'under', 'whom', 'shouldn', 'won', 'it', 'them', 'your', 'about', 'd', 'shan', \"haven't\", 'herself', 'isn', 'or', 'did', 'has', 'off', 'that', 'not', 'aren', \"you're\", 'for', 'nor', \"shouldn't\", 'can', 'its', \"you'd\", 'itself', 'being', 'my', 'am', 'more', 'what'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = list()\n",
        "for i in range(len(df)):\n",
        "    li = df.Text[i].split()\n",
        "    for k in li:\n",
        "        word_list.append(k)"
      ],
      "metadata": {
        "id": "wvZgm8lsX6Vd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter \n",
        "wordCounter = Counter(word_list)\n",
        "countedWordDict = dict(wordCounter)\n",
        "sortedWordDict = sorted(countedWordDict.items(),key = lambda x : x[1],reverse=True)\n",
        "sortedWordDict[0:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2gNInCVYRWE",
        "outputId": "77b5bb46-0f92-4041-c0e6-756fdf57a293"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 1796),\n",
              " ('to', 1668),\n",
              " ('a', 1280),\n",
              " ('on', 1032),\n",
              " ('of', 944),\n",
              " ('in', 891),\n",
              " ('AAP', 884),\n",
              " ('for', 868),\n",
              " ('and', 850),\n",
              " ('is', 811),\n",
              " ('-', 728),\n",
              " ('at', 541),\n",
              " ('this', 461),\n",
              " ('it', 454),\n",
              " ('I', 453),\n",
              " ('up', 357),\n",
              " ('user:', 340),\n",
              " ('from', 331),\n",
              " ('will', 330),\n",
              " ('be', 324)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "H_LzksshTonY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 170204066\n",
        "torch.manual_seed(seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRp021h6XnK1",
        "outputId": "de37203f-0483-45ce-e15c-e8f60f111a14"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f21bee7e790>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Sentiment\"] = df[\"Sentiment\"].replace(-1,0)\n",
        "df[\"Sentiment\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgSwGmtMXsaE",
        "outputId": "48763588-8ee6-4234-c369-bd80841128c6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    3685\n",
              "0    2106\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if any null values present\n",
        "(df.isnull().sum() / len(df))*100"
      ],
      "metadata": {
        "id": "acrcdE-HT8Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps = PorterStemmer()\n",
        "lemma = WordNetLemmatizer()\n",
        "stopwordSet = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "cCv09jcdYkLW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "urlPattern = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
        "userPattern = '@[^\\s]+'\n",
        "def process_text(text):\n",
        "  # Lower Casing\n",
        "    text = text.lower()\n",
        "    text=text[1:]\n",
        "    # Removing all URls \n",
        "    text = re.sub(urlPattern,'',text)\n",
        "    # Removing all @username.\n",
        "    text = re.sub(userPattern,'',text) \n",
        "    #Remove punctuations\n",
        "    text = text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
        "    #tokenizing words\n",
        "    tokens = word_tokenize(text)\n",
        "    #Removing Stop Words\n",
        "    final_tokens = [w for w in tokens if w not in stopwordSet]\n",
        "    #reducing a word to its word stem \n",
        "    wordLemm = WordNetLemmatizer()\n",
        "    finalwords=[]\n",
        "    for w in final_tokens:\n",
        "      if len(w)>1:\n",
        "        word = wordLemm.lemmatize(w)\n",
        "        finalwords.append(word)\n",
        "    return ' '.join(finalwords)   "
      ],
      "metadata": {
        "id": "iArwDhlSYysL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['processed_text'] = df['Text'].apply(lambda x: process_text(x))\n",
        "print('Text Preprocessing complete.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPQ6neeKYFR_",
        "outputId": "aec5d3ff-bfe3-42d5-8d8e-9d37addae985"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Preprocessing complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "bFuchKvQeeqd",
        "outputId": "c55926bb-d6de-4256-afd9-967094742d32"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5791, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f8fbdaed-f0f4-4a51-b35d-b3645ef95053\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
              "      <td>1</td>\n",
              "      <td>ickers watchlist xide tit soq pnk cpw bpz aj t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
              "      <td>1</td>\n",
              "      <td>ser aap movie 55 return feageed indicator 15 t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
              "      <td>1</td>\n",
              "      <td>ser id afraid short amzn looking like nearmono...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MNTA Over 12.00</td>\n",
              "      <td>1</td>\n",
              "      <td>nta 1200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OI  Over 21.37</td>\n",
              "      <td>1</td>\n",
              "      <td>2137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5786</th>\n",
              "      <td>Industry body CII said #discoms are likely to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>ndustry body cii said discoms likely suffer ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5787</th>\n",
              "      <td>#Gold prices slip below Rs 46,000 as #investor...</td>\n",
              "      <td>0</td>\n",
              "      <td>gold price slip r 46000 investor book profit a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5788</th>\n",
              "      <td>Workers at Bajaj Auto have agreed to a 10% wag...</td>\n",
              "      <td>1</td>\n",
              "      <td>orkers bajaj auto agreed 10 wage cut period ap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5789</th>\n",
              "      <td>#Sharemarket LIVE: Sensex off day’s high, up 6...</td>\n",
              "      <td>1</td>\n",
              "      <td>sharemarket live sensex day high 600 point nif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5790</th>\n",
              "      <td>#Sensex, #Nifty climb off day's highs, still u...</td>\n",
              "      <td>1</td>\n",
              "      <td>sensex nifty climb day high still key factor d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5791 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8fbdaed-f0f4-4a51-b35d-b3645ef95053')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8fbdaed-f0f4-4a51-b35d-b3645ef95053 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8fbdaed-f0f4-4a51-b35d-b3645ef95053');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   Text  ...                                     processed_text\n",
              "0     Kickers on my watchlist XIDE TIT SOQ PNK CPW B...  ...  ickers watchlist xide tit soq pnk cpw bpz aj t...\n",
              "1     user: AAP MOVIE. 55% return for the FEA/GEED i...  ...  ser aap movie 55 return feageed indicator 15 t...\n",
              "2     user I'd be afraid to short AMZN - they are lo...  ...  ser id afraid short amzn looking like nearmono...\n",
              "3                                     MNTA Over 12.00    ...                                           nta 1200\n",
              "4                                      OI  Over 21.37    ...                                               2137\n",
              "...                                                 ...  ...                                                ...\n",
              "5786  Industry body CII said #discoms are likely to ...  ...  ndustry body cii said discoms likely suffer ne...\n",
              "5787  #Gold prices slip below Rs 46,000 as #investor...  ...  gold price slip r 46000 investor book profit a...\n",
              "5788  Workers at Bajaj Auto have agreed to a 10% wag...  ...  orkers bajaj auto agreed 10 wage cut period ap...\n",
              "5789  #Sharemarket LIVE: Sensex off day’s high, up 6...  ...  sharemarket live sensex day high 600 point nif...\n",
              "5790  #Sensex, #Nifty climb off day's highs, still u...  ...  sensex nifty climb day high still key factor d...\n",
              "\n",
              "[5791 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the (B.O.W) bag of word model"
      ],
      "metadata": {
        "id": "0JcofI1qmC0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer(max_features = len(df))\n",
        "X = cv.fit_transform(df['processed_text']).toarray()\n",
        "y= df['Sentiment'].to_numpy()\n",
        "\n",
        "#X = torch.from_numpy(X).type(torch.LongTensor)\n",
        "#y = torch.from_numpy(y).type(torch.LongTensor)\n",
        "\n",
        "X = torch.from_numpy(X)\n",
        "y = torch.from_numpy(y)\n"
      ],
      "metadata": {
        "id": "BEpKARyfZUs-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elder-scholarship",
        "papermill": {
          "duration": 0.081183,
          "end_time": "2021-04-17T08:43:33.846528",
          "exception": false,
          "start_time": "2021-04-17T08:43:33.765345",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Split train and test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fallen-gibraltar",
        "papermill": {
          "duration": 0.081915,
          "end_time": "2021-04-17T08:43:34.010048",
          "exception": false,
          "start_time": "2021-04-17T08:43:33.928133",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "The Preprocessed Data is divided into 2 sets of data:\n",
        "\n",
        "* Training Data: The dataset upon which the model would be trained on. Contains 80% data.\n",
        "* Test Data: The dataset upon which the model would be tested against. Contains 20% data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Split the dataset into Training and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2, random_state = seed)\n",
        "\n",
        "X_train = X_train.type(torch.FloatTensor)\n",
        "X_test = X_test.type(torch.FloatTensor)\n",
        "y_train = y_train.type(torch.FloatTensor)\n",
        "y_test = y_test.type(torch.FloatTensor)"
      ],
      "metadata": {
        "id": "XOAKipE9n2hb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#BATCH_SIZE = 264\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n"
      ],
      "metadata": {
        "id": "Z6ISSPHXr1Nr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "expressed-antenna",
        "papermill": {
          "duration": 0.08273,
          "end_time": "2021-04-17T08:43:34.573838",
          "exception": false,
          "start_time": "2021-04-17T08:43:34.491108",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Model Building <a id=\"7\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Neural Network**"
      ],
      "metadata": {
        "id": "TfF59Fw2oXst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.layer_1 = nn.Linear(input_dim, 512) \n",
        "        self.layer_2 = nn.Linear(512, 128) \n",
        "        self.layer_3 = nn.Linear(128, 1)   \n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.dropout = nn.Dropout()\n",
        "        # self.flatten = nn.Flatten()\n",
        "       \n",
        "     \n",
        "  \n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.layer_1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer_3(x)\n",
        "        logits = self.sigmoid(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "d6yywd_wZ582"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork(len(df))\n",
        "print(model)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_hR0V6Ybxwd",
        "outputId": "108bca65-078c-4efb-e0cd-5d32270f7a94"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (layer_1): Linear(in_features=5791, out_features=512, bias=True)\n",
            "  (layer_2): Linear(in_features=512, out_features=128, bias=True)\n",
            "  (layer_3): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (sigmoid): Sigmoid()\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization"
      ],
      "metadata": {
        "id": "LRkQo8pBqCc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "loss_fn = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "model = model.to(device)\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "uH9iXuuKb_lU"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We implement the function to calculate accuracy..."
      ],
      "metadata": {
        "id": "ArUL6oeYp91U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "WJvyCQFfp7JM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def trainModel(model, loss_fn, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    batch = 256\n",
        "    size = X_test.shape[0]\n",
        "\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    \n",
        "\n",
        "    for i in range(X_train.shape[0]):\n",
        "      x, y = X_train[i], torch.tensor([y_train[i]], dtype=torch.float)\n",
        "    \n",
        "      # Compute prediction \n",
        "      pred = model(x)\n",
        "      loss += loss_fn(pred,y)\n",
        "      acc += binary_accuracy(pred,y)\n",
        "      \n",
        "      if i>0 and (i+1)%batch == 0:\n",
        "          # Backpropagation\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "         # print(f'Training Loss: {loss.item():.4f}', end=\"\\r\")\n",
        "         # print(f'\\tTraining Loss: {loss.item():.3f} | Training Acc: {acc.item()*100:.2f}%')\n",
        "          loss = 0\n",
        "          acc = 0\n",
        "    print()\n",
        "    return loss.item()/size, acc.item()/size\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yOdkm0QxcBiu"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.lib.function_base import append\n",
        "\n",
        "\n",
        "TP=[]\n",
        "TN=[]\n",
        "FP=[]\n",
        "FN=[]\n",
        "def testModel(model, loss_fn):\n",
        "    model.eval()\n",
        "\n",
        "    size = X_test.shape[0]\n",
        "\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for i in range(X_test.shape[0]):\n",
        "        x, y = X_test[i], torch.tensor([y_test[i]], dtype=torch.float)\n",
        "    \n",
        "        # Compute prediction error\n",
        "        pred = model(x)\n",
        "        if( (torch.round(pred)) == 1 and y== 0) :\n",
        "           FP.append(1)\n",
        "        if( (torch.round(pred)) == 0 and y== 1) :\n",
        "           FN.append(1)\n",
        "        if( (torch.round(pred)) == 1 and y== 1) :\n",
        "           TP.append(1)\n",
        "        if( (torch.round(pred)) == 0 and y== 0) :\n",
        "           TP.append(1)         \n",
        "       \n",
        "            \n",
        "        loss += loss_fn(pred, y).item()\n",
        "        acc += binary_accuracy(pred,y).item()\n",
        "      \n",
        "    loss /= size\n",
        "    acc /= size\n",
        "    \n",
        "    #print(f'Testing Loss: {loss}')\n",
        "    #print(f'\\t Val. Loss: {loss:.3f} |  Val. Acc: {acc*100:.2f}%')\n",
        "  \n",
        "    return loss, acc  "
      ],
      "metadata": {
        "id": "eHL5jt3sdRj0"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at9dIR_jTwYU"
      },
      "source": [
        "And also create a nice function to tell us how long our epochs are taking."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1score"
      ],
      "metadata": {
        "id": "YcjlyDuisO_-",
        "outputId": "537d39bf-345e-48a7-abdb-d3074d14eecd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8631682197155469"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8fkDm20n-iqu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}